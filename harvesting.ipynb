{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harvesting @ MLAI Training - First Round Overview\n",
    "\n",
    "This experiment trains an XGB model to distinguish harvesting sessions from ordinary sessions. In this model, we use a simplified representation of user sessions based on the common bag-of-words representation. This representation discards sequences and timing, reducing a user session to a row of counts for each transaction type.\n",
    "\n",
    "While this was the first attempt to train a model to recognize the activity of a known harvester, the techniques proved quite successful. The approach successfully distinguished 85% of the activity of the harvester with 0 false positives.\n",
    "\n",
    "The rest of this document describes and implements the experiment, closing with some suggested next steps.\n",
    "\n",
    "## Training Data\n",
    "The training dataset consists of several hours of raw transaction logs containing activity from all users, with the full collection of harvesting activity from the LiquidTension harvester across two years. All LiquidTension(LT) activity is labeled as 'BadActor' = 1, while all other traffic is assumed to be innocent and labeled as 'BadActor' = 0. Since LiquidTension is currently our only easily-identified single harvester, we need his full range of activity to have a BadActor sessions in proportion to innocent sessions for training to work properly.\n",
    "\n",
    "The training set includes the following files:\n",
    "\n",
    "|File       |Contents                             |Rows|\n",
    "------------|-------------------------------------|----|\n",
    "|may1.tsv|raw transactions|119474|\n",
    "|may2.tsv|raw transactions|43608|\n",
    "|may3.tsv|raw transactions|30844|\n",
    "|lt-only.tsv|raw transactions for a known attacker|61917|\n",
    "\n",
    "In all, we have 193926 transactions from \"innocent\" sessions and 61917 LT sessions. Approximately 32% of transactions are labeled BadActor = 1, giving us a reasonable proportion in both classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm up\n",
    "Import standard libraries and prepare the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sagemaker session, role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# S3 bucket name\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download\n",
    "Retrieve the datafiles from the project's designated S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SessionNo</th>\n",
       "      <th>LogTime</th>\n",
       "      <th>CustID</th>\n",
       "      <th>GroupID</th>\n",
       "      <th>ProfID</th>\n",
       "      <th>Act</th>\n",
       "      <th>BadActor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7704</th>\n",
       "      <td>-40132942</td>\n",
       "      <td>2019-05-01 19:18:52.000</td>\n",
       "      <td>s8873650</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7707</th>\n",
       "      <td>-1</td>\n",
       "      <td>2019-05-01 19:18:53.000</td>\n",
       "      <td>s8873650</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7863</th>\n",
       "      <td>-40132942</td>\n",
       "      <td>2019-05-01 19:19:22.000</td>\n",
       "      <td>s8873650</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8391</th>\n",
       "      <td>-1</td>\n",
       "      <td>2019-05-01 19:20:29.000</td>\n",
       "      <td>s8875270</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8396</th>\n",
       "      <td>1731108217</td>\n",
       "      <td>2019-05-01 19:20:29.000</td>\n",
       "      <td>s8875270</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8722</th>\n",
       "      <td>1731108217</td>\n",
       "      <td>2019-05-01 19:21:07.000</td>\n",
       "      <td>s8875270</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8963</th>\n",
       "      <td>401087102</td>\n",
       "      <td>2019-05-01 19:21:51.000</td>\n",
       "      <td>s8875834</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8968</th>\n",
       "      <td>-1</td>\n",
       "      <td>2019-05-01 19:21:52.000</td>\n",
       "      <td>s8875834</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9356</th>\n",
       "      <td>401087102</td>\n",
       "      <td>2019-05-01 19:22:47.000</td>\n",
       "      <td>s8875834</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9690</th>\n",
       "      <td>401087102</td>\n",
       "      <td>2019-05-01 19:23:39.000</td>\n",
       "      <td>s8875834</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9809</th>\n",
       "      <td>401087102</td>\n",
       "      <td>2019-05-01 19:23:58.000</td>\n",
       "      <td>s8875834</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>407</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9813</th>\n",
       "      <td>401087102</td>\n",
       "      <td>2019-05-01 19:23:58.000</td>\n",
       "      <td>s8875834</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>406</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9818</th>\n",
       "      <td>401087102</td>\n",
       "      <td>2019-05-01 19:24:00.000</td>\n",
       "      <td>s8875834</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>407</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9820</th>\n",
       "      <td>401087102</td>\n",
       "      <td>2019-05-01 19:24:00.000</td>\n",
       "      <td>s8875834</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>406</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9821</th>\n",
       "      <td>401087102</td>\n",
       "      <td>2019-05-01 19:24:00.000</td>\n",
       "      <td>s8875834</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9823</th>\n",
       "      <td>401087102</td>\n",
       "      <td>2019-05-01 19:24:00.000</td>\n",
       "      <td>s8875834</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9857</th>\n",
       "      <td>401087102</td>\n",
       "      <td>2019-05-01 19:24:06.000</td>\n",
       "      <td>s8875834</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9858</th>\n",
       "      <td>401087102</td>\n",
       "      <td>2019-05-01 19:24:06.000</td>\n",
       "      <td>s8875834</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>401087102</td>\n",
       "      <td>2019-05-01 19:24:34.000</td>\n",
       "      <td>s8875834</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>406</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>401087102</td>\n",
       "      <td>2019-05-01 19:24:34.000</td>\n",
       "      <td>s8875834</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>407</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10017</th>\n",
       "      <td>401087102</td>\n",
       "      <td>2019-05-01 19:24:36.000</td>\n",
       "      <td>s8875834</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10024</th>\n",
       "      <td>401087102</td>\n",
       "      <td>2019-05-01 19:24:36.000</td>\n",
       "      <td>s8875834</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10025</th>\n",
       "      <td>401087102</td>\n",
       "      <td>2019-05-01 19:24:36.000</td>\n",
       "      <td>s8875834</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>407</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10027</th>\n",
       "      <td>401087102</td>\n",
       "      <td>2019-05-01 19:24:36.000</td>\n",
       "      <td>s8875834</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>406</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10047</th>\n",
       "      <td>401087102</td>\n",
       "      <td>2019-05-01 19:24:40.000</td>\n",
       "      <td>s8875834</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10048</th>\n",
       "      <td>401087102</td>\n",
       "      <td>2019-05-01 19:24:40.000</td>\n",
       "      <td>s8875834</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10222</th>\n",
       "      <td>401087102</td>\n",
       "      <td>2019-05-01 19:25:04.000</td>\n",
       "      <td>s8875834</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>407</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10225</th>\n",
       "      <td>401087102</td>\n",
       "      <td>2019-05-01 19:25:04.000</td>\n",
       "      <td>s8875834</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>406</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10238</th>\n",
       "      <td>401087102</td>\n",
       "      <td>2019-05-01 19:25:06.000</td>\n",
       "      <td>s8875834</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>406</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10241</th>\n",
       "      <td>401087102</td>\n",
       "      <td>2019-05-01 19:25:06.000</td>\n",
       "      <td>s8875834</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61887</th>\n",
       "      <td>260325137</td>\n",
       "      <td>2019-06-11 23:15:10.000</td>\n",
       "      <td>s6094266</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61888</th>\n",
       "      <td>260325137</td>\n",
       "      <td>2019-06-11 23:15:46.000</td>\n",
       "      <td>s6094266</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>311</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61889</th>\n",
       "      <td>260325137</td>\n",
       "      <td>2019-06-11 23:16:02.000</td>\n",
       "      <td>s6094266</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61890</th>\n",
       "      <td>351936774</td>\n",
       "      <td>2019-06-11 23:16:38.000</td>\n",
       "      <td>s6146994</td>\n",
       "      <td>main</td>\n",
       "      <td>ebooks</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61891</th>\n",
       "      <td>351936774</td>\n",
       "      <td>2019-06-11 23:16:45.000</td>\n",
       "      <td>s6146994</td>\n",
       "      <td>main</td>\n",
       "      <td>ebooks</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61892</th>\n",
       "      <td>351936774</td>\n",
       "      <td>2019-06-11 23:22:51.000</td>\n",
       "      <td>s6146994</td>\n",
       "      <td>main</td>\n",
       "      <td>ebooks</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61893</th>\n",
       "      <td>351936774</td>\n",
       "      <td>2019-06-11 23:22:51.000</td>\n",
       "      <td>s6146994</td>\n",
       "      <td>main</td>\n",
       "      <td>ebooks</td>\n",
       "      <td>311</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61894</th>\n",
       "      <td>-98975912</td>\n",
       "      <td>2019-06-11 23:25:56.000</td>\n",
       "      <td>s6184355</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61895</th>\n",
       "      <td>-98975912</td>\n",
       "      <td>2019-06-11 23:26:18.000</td>\n",
       "      <td>s6184355</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>311</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61896</th>\n",
       "      <td>-98975912</td>\n",
       "      <td>2019-06-11 23:27:01.000</td>\n",
       "      <td>s6184355</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61897</th>\n",
       "      <td>-98975912</td>\n",
       "      <td>2019-06-11 23:29:03.000</td>\n",
       "      <td>s6184355</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61898</th>\n",
       "      <td>-98975912</td>\n",
       "      <td>2019-06-11 23:29:30.000</td>\n",
       "      <td>s6184355</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>407</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61899</th>\n",
       "      <td>-98975912</td>\n",
       "      <td>2019-06-11 23:29:30.000</td>\n",
       "      <td>s6184355</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>406</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61900</th>\n",
       "      <td>-98975912</td>\n",
       "      <td>2019-06-11 23:30:20.000</td>\n",
       "      <td>s6184355</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>407</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61901</th>\n",
       "      <td>-98975912</td>\n",
       "      <td>2019-06-11 23:30:20.000</td>\n",
       "      <td>s6184355</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61902</th>\n",
       "      <td>-98975912</td>\n",
       "      <td>2019-06-11 23:30:20.000</td>\n",
       "      <td>s6184355</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>406</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61903</th>\n",
       "      <td>-98975912</td>\n",
       "      <td>2019-06-11 23:30:20.000</td>\n",
       "      <td>s6184355</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61904</th>\n",
       "      <td>-98975912</td>\n",
       "      <td>2019-06-11 23:31:34.000</td>\n",
       "      <td>s6184355</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>406</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61905</th>\n",
       "      <td>-98975912</td>\n",
       "      <td>2019-06-11 23:31:34.000</td>\n",
       "      <td>s6184355</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>407</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61906</th>\n",
       "      <td>-98975912</td>\n",
       "      <td>2019-06-11 23:31:37.000</td>\n",
       "      <td>s6184355</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61907</th>\n",
       "      <td>-98975912</td>\n",
       "      <td>2019-06-11 23:31:37.000</td>\n",
       "      <td>s6184355</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61908</th>\n",
       "      <td>-98975912</td>\n",
       "      <td>2019-06-11 23:31:37.000</td>\n",
       "      <td>s6184355</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>407</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61909</th>\n",
       "      <td>-98975912</td>\n",
       "      <td>2019-06-11 23:31:37.000</td>\n",
       "      <td>s6184355</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>406</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61910</th>\n",
       "      <td>-98975912</td>\n",
       "      <td>2019-06-11 23:33:07.000</td>\n",
       "      <td>s6184355</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61911</th>\n",
       "      <td>-98975912</td>\n",
       "      <td>2019-06-11 23:33:46.000</td>\n",
       "      <td>s6184355</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>407</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61912</th>\n",
       "      <td>-98975912</td>\n",
       "      <td>2019-06-11 23:33:46.000</td>\n",
       "      <td>s6184355</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>406</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61913</th>\n",
       "      <td>-98975912</td>\n",
       "      <td>2019-06-11 23:33:50.000</td>\n",
       "      <td>s6184355</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>406</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61914</th>\n",
       "      <td>-98975912</td>\n",
       "      <td>2019-06-11 23:33:50.000</td>\n",
       "      <td>s6184355</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>407</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61915</th>\n",
       "      <td>-98975912</td>\n",
       "      <td>2019-06-11 23:33:50.000</td>\n",
       "      <td>s6184355</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61916</th>\n",
       "      <td>-98975912</td>\n",
       "      <td>2019-06-11 23:33:50.000</td>\n",
       "      <td>s6184355</td>\n",
       "      <td>main</td>\n",
       "      <td>ehost</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62450 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SessionNo                  LogTime    CustID GroupID  ProfID  Act  \\\n",
       "7704    -40132942  2019-05-01 19:18:52.000  s8873650    main   ehost  111   \n",
       "7707           -1  2019-05-01 19:18:53.000  s8873650    main   ehost  201   \n",
       "7863    -40132942  2019-05-01 19:19:22.000  s8873650    main   ehost  121   \n",
       "8391           -1  2019-05-01 19:20:29.000  s8875270    main   ehost  201   \n",
       "8396   1731108217  2019-05-01 19:20:29.000  s8875270    main   ehost  111   \n",
       "8722   1731108217  2019-05-01 19:21:07.000  s8875270    main   ehost  121   \n",
       "8963    401087102  2019-05-01 19:21:51.000  s8875834    main   ehost  111   \n",
       "8968           -1  2019-05-01 19:21:52.000  s8875834    main   ehost  201   \n",
       "9356    401087102  2019-05-01 19:22:47.000  s8875834    main   ehost  121   \n",
       "9690    401087102  2019-05-01 19:23:39.000  s8875834    main   ehost  124   \n",
       "9809    401087102  2019-05-01 19:23:58.000  s8875834    main   ehost  407   \n",
       "9813    401087102  2019-05-01 19:23:58.000  s8875834    main   ehost  406   \n",
       "9818    401087102  2019-05-01 19:24:00.000  s8875834    main   ehost  407   \n",
       "9820    401087102  2019-05-01 19:24:00.000  s8875834    main   ehost  406   \n",
       "9821    401087102  2019-05-01 19:24:00.000  s8875834    main   ehost  135   \n",
       "9823    401087102  2019-05-01 19:24:00.000  s8875834    main   ehost  115   \n",
       "9857    401087102  2019-05-01 19:24:06.000  s8875834    main   ehost  115   \n",
       "9858    401087102  2019-05-01 19:24:06.000  s8875834    main   ehost  135   \n",
       "10000   401087102  2019-05-01 19:24:34.000  s8875834    main   ehost  406   \n",
       "10003   401087102  2019-05-01 19:24:34.000  s8875834    main   ehost  407   \n",
       "10017   401087102  2019-05-01 19:24:36.000  s8875834    main   ehost  115   \n",
       "10024   401087102  2019-05-01 19:24:36.000  s8875834    main   ehost  135   \n",
       "10025   401087102  2019-05-01 19:24:36.000  s8875834    main   ehost  407   \n",
       "10027   401087102  2019-05-01 19:24:36.000  s8875834    main   ehost  406   \n",
       "10047   401087102  2019-05-01 19:24:40.000  s8875834    main   ehost  115   \n",
       "10048   401087102  2019-05-01 19:24:40.000  s8875834    main   ehost  135   \n",
       "10222   401087102  2019-05-01 19:25:04.000  s8875834    main   ehost  407   \n",
       "10225   401087102  2019-05-01 19:25:04.000  s8875834    main   ehost  406   \n",
       "10238   401087102  2019-05-01 19:25:06.000  s8875834    main   ehost  406   \n",
       "10241   401087102  2019-05-01 19:25:06.000  s8875834    main   ehost  115   \n",
       "...           ...                      ...       ...     ...     ...  ...   \n",
       "61887   260325137  2019-06-11 23:15:10.000  s6094266    main   ehost  111   \n",
       "61888   260325137  2019-06-11 23:15:46.000  s6094266    main   ehost  311   \n",
       "61889   260325137  2019-06-11 23:16:02.000  s6094266    main   ehost  121   \n",
       "61890   351936774  2019-06-11 23:16:38.000  s6146994    main  ebooks  111   \n",
       "61891   351936774  2019-06-11 23:16:45.000  s6146994    main  ebooks  121   \n",
       "61892   351936774  2019-06-11 23:22:51.000  s6146994    main  ebooks  123   \n",
       "61893   351936774  2019-06-11 23:22:51.000  s6146994    main  ebooks  311   \n",
       "61894   -98975912  2019-06-11 23:25:56.000  s6184355    main   ehost  111   \n",
       "61895   -98975912  2019-06-11 23:26:18.000  s6184355    main   ehost  311   \n",
       "61896   -98975912  2019-06-11 23:27:01.000  s6184355    main   ehost  121   \n",
       "61897   -98975912  2019-06-11 23:29:03.000  s6184355    main   ehost  124   \n",
       "61898   -98975912  2019-06-11 23:29:30.000  s6184355    main   ehost  407   \n",
       "61899   -98975912  2019-06-11 23:29:30.000  s6184355    main   ehost  406   \n",
       "61900   -98975912  2019-06-11 23:30:20.000  s6184355    main   ehost  407   \n",
       "61901   -98975912  2019-06-11 23:30:20.000  s6184355    main   ehost  135   \n",
       "61902   -98975912  2019-06-11 23:30:20.000  s6184355    main   ehost  406   \n",
       "61903   -98975912  2019-06-11 23:30:20.000  s6184355    main   ehost  115   \n",
       "61904   -98975912  2019-06-11 23:31:34.000  s6184355    main   ehost  406   \n",
       "61905   -98975912  2019-06-11 23:31:34.000  s6184355    main   ehost  407   \n",
       "61906   -98975912  2019-06-11 23:31:37.000  s6184355    main   ehost  115   \n",
       "61907   -98975912  2019-06-11 23:31:37.000  s6184355    main   ehost  135   \n",
       "61908   -98975912  2019-06-11 23:31:37.000  s6184355    main   ehost  407   \n",
       "61909   -98975912  2019-06-11 23:31:37.000  s6184355    main   ehost  406   \n",
       "61910   -98975912  2019-06-11 23:33:07.000  s6184355    main   ehost  123   \n",
       "61911   -98975912  2019-06-11 23:33:46.000  s6184355    main   ehost  407   \n",
       "61912   -98975912  2019-06-11 23:33:46.000  s6184355    main   ehost  406   \n",
       "61913   -98975912  2019-06-11 23:33:50.000  s6184355    main   ehost  406   \n",
       "61914   -98975912  2019-06-11 23:33:50.000  s6184355    main   ehost  407   \n",
       "61915   -98975912  2019-06-11 23:33:50.000  s6184355    main   ehost  115   \n",
       "61916   -98975912  2019-06-11 23:33:50.000  s6184355    main   ehost  135   \n",
       "\n",
       "       BadActor  \n",
       "7704          1  \n",
       "7707          1  \n",
       "7863          1  \n",
       "8391          1  \n",
       "8396          1  \n",
       "8722          1  \n",
       "8963          1  \n",
       "8968          1  \n",
       "9356          1  \n",
       "9690          1  \n",
       "9809          1  \n",
       "9813          1  \n",
       "9818          1  \n",
       "9820          1  \n",
       "9821          1  \n",
       "9823          1  \n",
       "9857          1  \n",
       "9858          1  \n",
       "10000         1  \n",
       "10003         1  \n",
       "10017         1  \n",
       "10024         1  \n",
       "10025         1  \n",
       "10027         1  \n",
       "10047         1  \n",
       "10048         1  \n",
       "10222         1  \n",
       "10225         1  \n",
       "10238         1  \n",
       "10241         1  \n",
       "...         ...  \n",
       "61887         1  \n",
       "61888         1  \n",
       "61889         1  \n",
       "61890         1  \n",
       "61891         1  \n",
       "61892         1  \n",
       "61893         1  \n",
       "61894         1  \n",
       "61895         1  \n",
       "61896         1  \n",
       "61897         1  \n",
       "61898         1  \n",
       "61899         1  \n",
       "61900         1  \n",
       "61901         1  \n",
       "61902         1  \n",
       "61903         1  \n",
       "61904         1  \n",
       "61905         1  \n",
       "61906         1  \n",
       "61907         1  \n",
       "61908         1  \n",
       "61909         1  \n",
       "61910         1  \n",
       "61911         1  \n",
       "61912         1  \n",
       "61913         1  \n",
       "61914         1  \n",
       "61915         1  \n",
       "61916         1  \n",
       "\n",
       "[62450 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "b = s3.Bucket('sagemaker-mlai-harvesting')\n",
    "\n",
    "# b.download_file( 'data/MLAI_ParsedDataSet.tsv', 'data/data.tsv')\n",
    "b.download_file( \"data/MinimalLogs/Minimal_May01.rpt\", 'data/may1.tsv')\n",
    "b.download_file( \"data/MinimalLogs/Minimal_May02.rpt\", 'data/may2.tsv')\n",
    "b.download_file( \"data/MinimalLogs/Minimal_May03.rpt\", 'data/may3.tsv')\n",
    "b.download_file( \"data/MinimalLogs/Minimal_OnlyLT.rpt\", 'data/lt-only.tsv')\n",
    "\n",
    "\n",
    "may1 = pd.read_csv('data/may1.tsv',sep='\\t')\n",
    "may2 = pd.read_csv('data/may2.tsv',sep='\\t')\n",
    "may3 = pd.read_csv('data/may3.tsv',sep='\\t')\n",
    "lt = pd.read_csv('data/lt-only.tsv',sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "bad_col='BadActor'\n",
    "sess_col='SessionNo'\n",
    "txn_col='Act'\n",
    "\n",
    "txn = may1.append([may2, may3, lt])\n",
    "txn[txn[bad_col]==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data conversion and feature engineering\n",
    "In real life, a session consists of a series of rows of transactions of different types, and each transaction type records a variable number of additional metadata attributes describing a logged event, for a total of over 30 columns of extracted data. In addition, our tagging process has given each row a BadActor label.\n",
    "\n",
    "|sessionno|txn id|BadActor|parm1|parm2|...|\n",
    "|---------|------|--------|-----|-----|---|\n",
    "|1240|111|0|query string|...|...|\n",
    "|1240|112|0|meta|...|...|\n",
    "|2993|301|1|meta|...|...|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Innocent' log entries\n",
    "txns = pd.DataFrame(np.sort(txn['Act'].unique()))\n",
    "\n",
    "# Harvesting log entries\n",
    "lt_txns = pd.DataFrame(np.sort(lt['Act'].unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We drop most of this information, including the temporal sequence of the log entries, and convert each session into a single row of data. Almost all of the columns go away, replaced by counts of transaction types in the session.\n",
    "\n",
    "|sessionno|BadActor|111|112|113|...|301|302|...|\n",
    "|---------|--------|---|---|---|---|---|---|---|\n",
    "|1240|0|1|1|0|...|0|0|...|\n",
    "|2993|1|0|0|0|...|1|0|...|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_txns( txn_log ):\n",
    "    txn_narrow = txn_log[[sess_col, txn_col,bad_col]]\n",
    "    txn_pivot = pd.pivot_table(txn_narrow, index=[sess_col,bad_col], columns = [txn_col],aggfunc=[len]).fillna(0)\n",
    "    txn_pivot.columns = txn_pivot.columns.droplevel(0)           # the pivot table has a two-level index\n",
    "    txn_flat = txn_pivot.rename_axis(None, axis=1).reset_index() # these two lines get rid of it so we have a simple table\n",
    "    return txn_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = flatten_txns( txn )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.download_file( \"data/MinimalLogs/Minimal_May08.rpt\", 'data/may8.tsv')\n",
    "may8 = pd.read_csv('data/may8.tsv',sep='\\t')\n",
    "flat_may8 = flatten_txns( txn )\n",
    "file = \"out/may8.csv\"\n",
    "\n",
    "flat_may8.to_csv(file)\n",
    "s3_client.upload_file(file, bucket, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Producing pools of training and testing data\n",
    "\n",
    "We will divide the combined good and bad data pools as follows:\n",
    "- a training set that the model iterates over during the learning process\n",
    "- a test set that is used to evaluate the model during training\n",
    "- a validation set that is kept separate to test the model after training is complete. We need separate test and validate pools in order to make sure that we're overfitting the model to a single set of test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_frame( df, train_frac ):\n",
    "    l = len(df)\n",
    "    test_frac = (1-train_frac)/2\n",
    "    tr = int(train_frac * l)\n",
    "    te = int(tr + test_frac * l)\n",
    "    \n",
    "    train = df[:tr]\n",
    "    test = df[tr:te]\n",
    "    val = df[te:]\n",
    "    return [train, test, val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_split( flat, bad_split=.8 ):\n",
    "    bad = flat[flat[bad_col]==1]\n",
    "    good = flat[flat[bad_col]==0]\n",
    "    \n",
    "    bads = split_frame(bad, bad_split)\n",
    "    goods = split_frame(good, bad_split)\n",
    "    \n",
    "    dfs = []\n",
    "    for i in range(3):\n",
    "        # Dropping the session # because we don't want to train on it.\n",
    "        # Also leaves our label - BadActor - in the 0 column, as XGBoost requires for CSV\n",
    "        df = bads[i].append(goods[i]).drop(sess_col,axis=1).sample(frac=1)\n",
    "        dfs.append( df )\n",
    "    \n",
    "    return dfs\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data and upload to S3\n",
    "Break the set into train, test, and validation collections and output CSV's.\n",
    "As Sagemaker requires, leave out row indices and column headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘out’: File exists\n",
      "Uploading out/train.csv to sagemaker-mlai-harvesting\n",
      "None\n",
      "Uploading out/test.csv to sagemaker-mlai-harvesting\n",
      "None\n",
      "Uploading out/validate.csv to sagemaker-mlai-harvesting\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dfs = train_split(flat_may8, .2)\n",
    "\n",
    "!mkdir out\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "bucket = \"sagemaker-mlai-harvesting\"\n",
    "\n",
    "for i, df in enumerate(dfs):\n",
    "    files = [\"train\",\"test\",\"validate\"]\n",
    "    file = \"out/{}.csv\".format(files[i])\n",
    "    df.to_csv(path_or_buf= file, header=False, index=False  )\n",
    "\n",
    "    print(\"Uploading {} to {}\".format(file, bucket))\n",
    "\n",
    "    response = s3_client.upload_file(file, bucket, file)\n",
    "    print(response)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare and train a model\n",
    "Boilerplate code mostly copied from Amazon sample code at https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/xgboost_abalone/xgboost_abalone.ipynb, with ample room for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job harvesting-xgboost-binary-classification2019-06-13-16-48-30\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "Completed\n",
      "CPU times: user 67.9 ms, sys: 3.89 ms, total: 71.8 ms\n",
      "Wall time: 3min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "region = 'us-east-1'\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(region, 'xgboost')\n",
    "\n",
    "\n",
    "from time import gmtime, strftime\n",
    "\n",
    "job_name = 'harvesting-xgboost-binary-classification' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"Training job\", job_name)\n",
    "\n",
    "#Ensure that the training and validation data folders generated above are reflected in the \"InputDataConfig\" parameter below.\n",
    "\n",
    "create_training_params = \\\n",
    "{\n",
    "    \"AlgorithmSpecification\": {\n",
    "        \"TrainingImage\": container,\n",
    "        \"TrainingInputMode\": \"File\"\n",
    "    },\n",
    "    \"RoleArn\": role,\n",
    "    \"OutputDataConfig\": {\n",
    "        \"S3OutputPath\": os.path.join(\"s3://\",bucket, \"out\", \"xgb-class\") \n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "        \"InstanceCount\": 1,\n",
    "        \"InstanceType\": \"ml.m4.4xlarge\",\n",
    "        \"VolumeSizeInGB\": 5\n",
    "    },\n",
    "    \"TrainingJobName\": job_name,\n",
    "    \"HyperParameters\": {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"silent\":\"0\",\n",
    "        \"objective\":\"binary:logistic\",\n",
    "        \"num_round\":\"50\"\n",
    "    },\n",
    "    \"StoppingCondition\": {\n",
    "        \"MaxRuntimeInSeconds\": 3600\n",
    "    },\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": \"s3://sagemaker-mlai-harvesting/out/train.csv\" , \n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"text/csv\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": \"s3://sagemaker-mlai-harvesting/out/validate.csv\" ,\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"text/csv\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "client = boto3.client('sagemaker', region_name=region)\n",
    "client.create_training_job(**create_training_params)\n",
    "\n",
    "import time\n",
    "\n",
    "status = client.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "print(status)\n",
    "while status !='Completed' and status!='Failed':\n",
    "    time.sleep(60)\n",
    "    status = client.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "    print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "harvesting-xgboost-binary-cl2019-06-13-16-48-30-model\n",
      "s3://sagemaker-mlai-harvesting/out/xgb-class/harvesting-xgboost-binary-classification2019-06-13-16-48-30/output/model.tar.gz\n",
      "arn:aws:sagemaker:us-east-1:872344130825:model/harvesting-xgboost-binary-cl2019-06-13-16-48-30-model\n",
      "CPU times: user 17.5 ms, sys: 0 ns, total: 17.5 ms\n",
      "Wall time: 270 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "model_name=\"harvesting-xgboost-binary-cl2019-06-13-16-48-30\"+ '-model'\n",
    "print(model_name)\n",
    "\n",
    "info = client.describe_training_job(TrainingJobName=job_name)\n",
    "model_data = info['ModelArtifacts']['S3ModelArtifacts']\n",
    "print(model_data)\n",
    "\n",
    "primary_container = {\n",
    "    'Image': container,\n",
    "    'ModelDataUrl': model_data\n",
    "}\n",
    "\n",
    "create_model_response = client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = primary_container)\n",
    "\n",
    "print(create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harvest-XGBoostEndpointConfig-2019-06-13-16-53-57\n",
      "Endpoint Config Arn: arn:aws:sagemaker:us-east-1:872344130825:endpoint-config/harvest-xgboostendpointconfig-2019-06-13-16-53-57\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "endpoint_config_name = 'Harvest-XGBoostEndpointConfig-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_config_name)\n",
    "create_endpoint_config_response = client.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'ml.m4.xlarge',\n",
    "        'InitialVariantWeight':1,\n",
    "        'InitialInstanceCount':1,\n",
    "        'ModelName':model_name,\n",
    "        'VariantName':'AllTraffic'}])\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response['EndpointConfigArn'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harvest-XGBoostEndpoint-2019-06-13-16-54-00\n",
      "arn:aws:sagemaker:us-east-1:872344130825:endpoint/harvest-xgboostendpoint-2019-06-13-16-54-00\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: InService\n",
      "Arn: arn:aws:sagemaker:us-east-1:872344130825:endpoint/harvest-xgboostendpoint-2019-06-13-16-54-00\n",
      "Status: InService\n",
      "CPU times: user 134 ms, sys: 16.6 ms, total: 151 ms\n",
      "Wall time: 9min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "endpoint_name = 'Harvest-XGBoostEndpoint-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_name)\n",
    "create_endpoint_response = client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name)\n",
    "print(create_endpoint_response['EndpointArn'])\n",
    "\n",
    "resp = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp['EndpointStatus']\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status=='Creating':\n",
    "    time.sleep(60)\n",
    "    resp = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp['EndpointStatus']\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp['EndpointArn'])\n",
    "print(\"Status: \" + status)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model\n",
    "Currently, we launch an endpoint to test the model. This endpoint includes a simple web service that takes POST request with rows of or model's X values - columns other than BadActor - and returns a corresponding list of Y values - BadActor predictions.\n",
    "\n",
    "The endpoint approach is most suitable to interactive use, such as possibly using the model to blacklist a harvesting session as soon as it is identified. For offline analysis, this should be reconfigured to run batch transform jobs instead, which are cheaper to run and more streamlined to invoke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_client = boto3.client('runtime.sagemaker', region_name=region)\n",
    "\n",
    "import json\n",
    "from itertools import islice\n",
    "import math\n",
    "import struct\n",
    "\n",
    "!head -10000 out/test.csv > out/single-test.csv\n",
    "\n",
    "file_name = 'out/single-test.csv' \n",
    "\n",
    "# file_name = \"out/may8.csv\"\n",
    "\n",
    "\n",
    "csv = pd.read_csv(file_name, header=None)\n",
    "csv.columns\n",
    "label = csv[0]\n",
    "csv = csv.drop(0,axis=1)\n",
    "\n",
    "single = \"out/single.csv\"\n",
    "\n",
    "csv.to_csv(path_or_buf=single, header=False, index=False)\n",
    "\n",
    "with open(single, 'r') as f:\n",
    "    payload = f.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = runtime_client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                   ContentType='text/csv', \n",
    "                                   Body=payload)\n",
    "result = response['Body'].read()\n",
    "result = result.decode(\"utf-8\")\n",
    "result = result.split(',')\n",
    "result = [round(float(i)) for i in result]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the confusion metrics\n",
    "\n",
    "A confusion matrix describes the proportions of true and false positives and negatives, together with some derived metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9657853810264385 precision: 1.0 recall 0.8360655737704918\n"
     ]
    }
   ],
   "source": [
    "comp = pd.concat( [label, pd.DataFrame(result)], axis = 1)\n",
    "comp.columns =[\"label\",'prediction']\n",
    "\n",
    "label_positive = comp['label'] == 1\n",
    "predict_positive = comp['prediction'] == 1\n",
    "\n",
    "tp = len( comp[label_positive & predict_positive])\n",
    "fp = len( comp[~label_positive & predict_positive])\n",
    "tn = len( comp[~label_positive & ~predict_positive])\n",
    "fn = len( comp[label_positive & ~predict_positive])\n",
    "m = len(comp)\n",
    "\n",
    "accuracy = (tp+tn)/m\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "\n",
    "print(\"accuracy: {} precision: {} recall {}\".format(accuracy, precision,recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1683, 0, 7632, 330, 9645)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp,fp,tn,fn, len(comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very first time we ran the model, we achieved strikingly successful rates of harvesting identification.\n",
    "The most significant number here is the recall of 84%, meaning that we successfully identified 84% of all harvesting sessions by looking only at counts of transaction types.\n",
    "\n",
    "This approach appears promising!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further investigating the data \n",
    "\n",
    "We had additional ideas for modeling the data while staying in this bag-of-transaction technique.\n",
    "1. Try some hyperparameter tuning to seem if the success rates can be trivially improved.\n",
    "1. Enrich the training data set in various ways - add colums to summarize total session time, average time/request, and so on.\n",
    "1. Perform some clustering analysis to try to identify common patterns of behavior other than LT. This may reveal the presence of other kinds of harvesting.\n",
    "\n",
    "## Qualifying the approach\n",
    "Can we use this approach to identify and blacklist harvesting sessions as they occur? Some notes:\n",
    "1. The approach must be resilient to easy efforts to evade. Does the accuracy of the identification drop if the attacker makes minor changes to his workflow?\n",
    "1. How long does it take to identify an attacker in real time? \n",
    "    1. Do we gain certainty soon enough to stop an attacker before he's done what he came to do?\n",
    "    2. Can we tag sessions accurately after the first N log entries, for instance?\n",
    "    \n",
    "## Designing an implemetation\n",
    "Design an architecture for identifying and intercepting harvesting activity in real time. Confirm data sources, manage impact to usage latency, model costs and ROI.\n",
    "\n",
    "In today's world, it would be less effective to perform real-time analysis on AWS, since all of our current content usage is on-prem. The algorithm used here, XGBoost, is performant on commodity hardware, so we may be able to run on standard VMs.\n",
    "\n",
    "In real-time analysis, we will face a stream of events from interleaved sessions. We will have to demultiplex these into individual event streams both for training and for prediction, implying some kind of windowing to capture and send sets of log entries as partial sessions. It's not clear how big the impact of this windowing will be on the accuracy of the models.\n",
    "\n",
    "# Other analytical techniques\n",
    "While this algorithm seems promising, we're throwing away a huge amount of intelligence before we start training, in the name of simplicity. We can evaluate what kind of gains we could achieve through more advanced techniques:\n",
    "- Stateful models like LSTM or CNN\n",
    "- more \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
